name: Ephemeral EKS Job

permissions:
  id-token: write
  contents: read

on: 
  workflow_dispatch:
    inputs:
      action:
        description: "Deployment action"
        required: true
        default: "deploy-and-destroy"
        type: choice
        options:
          - deploy-and-destroy
          - deploy
          - destroy 
      job_name:
        description: "Kubernetes Job name to wait for"
        required: false
        default: "example-job"
      job_namespace:
        description: "Kubernetes namespace for the job"
        required: false
        default: "default"

jobs:
  main:
    runs-on: ubuntu-latest
    env:
      AWS_REGION: us-east-1
    steps: 
      - name: Checkout 
        uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::125156866057:role/github-OICD
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Set up Terraform
        uses: hashicorp/setup-terraform@v3

      - name: Terraform Init
        if: ${{ github.event.inputs.action != 'destroy' }}
        working-directory: ./terraform/environments/dev
        run: terraform init

      - name: Proactively Import Existing IAM Roles and Policies
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          set -e
          ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
          cd ./terraform/environments/dev
          # Import EKS Node Instance Profile if exists in AWS and not in state
          if aws iam get-instance-profile --instance-profile-name aura-eks-node-role-instance-profile >/dev/null 2>&1; then 
            if ! terraform state list | grep -q "module.iam_eks.aws_iam_instance_profile.eks_node_instance_profile"; then
              terraform import 'module.iam_eks.aws_iam_instance_profile.eks_node_instance_profile' aura-eks-node-role-instance-profile || true
            fi
          fi  

          # Import EKS Cluster Role if exists in AWS and not in state
          if aws iam get-role --role-name aura-eks-cluster-role >/dev/null 2>&1; then
            if ! terraform state list | grep -q "module.iam_eks.aws_iam_role.eks_cluster_role"; then
              terraform import 'module.iam_eks.aws_iam_role.eks_cluster_role' aura-eks-cluster-role || true
            fi
          fi

          # Import EKS Node Role if exists in AWS and not in state
          if aws iam get-role --role-name aura-eks-node-role >/dev/null 2>&1; then
            if ! terraform state list | grep -q "module.iam_eks.aws_iam_role.eks_node_role"; then
              terraform import 'module.iam_eks.aws_iam_role.eks_node_role' aura-eks-node-role || true
            fi
          fi

          # Import Karpenter Controller Policy if exists in AWS and not in state
          if aws iam get-policy --policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/aura-karpenter-controller-role-policy >/dev/null 2>&1; then
            if ! terraform state list | grep -q "module.iam.aws_iam_policy.karpenter_controller_inline"; then
              terraform import 'module.iam.aws_iam_policy.karpenter_controller_inline' arn:aws:iam::${ACCOUNT_ID}:policy/aura-karpenter-controller-role-policy || true
            fi
          fi
          # Import EKS Node Instance Profile if exists in AWS and not in state
          if aws iam get-instance-profile --instance-profile-name aura-eks-node-role-instance-profile >/dev/null 2>&1; then 
            if ! terraform state list | grep -q "module.iam_eks.aws_iam_instance_profile.eks_node_instance_profile"; then
               terraform import 'module.iam_eks.aws_iam_instance_profile.eks_node_instance_profile' aura-eks-node-role-instance-profile || true
            fi
          fi
        shell: bash
        continue-on-error: true

      - name: Terraform Plan 
        if: ${{ github.event.inputs.action != 'destroy' }}
        working-directory: ./terraform/environments/dev
        run: terraform plan -out=tfplan

      - name: Terraform Apply 
        if: ${{ github.event.inputs.action != 'destroy' }}
        working-directory: ./terraform/environments/dev
        run: terraform apply -auto-approve
        continue-on-error: false

      - name: Terraform Output
        if: ${{ github.event.inputs.action != 'destroy' }}
        working-directory: ./terraform/environments/dev
        run: |
          terraform output -json > tf-outputs.json
          if [ ! -s tf-outputs.json ]; then
            echo "tf-outputs.json missing or empty! Terraform apply likely failed."
            exit 1
          fi
        continue-on-error: false

      - name: Validate Terraform Outputs
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          set -euo pipefail
          echo "Validating tf-outputs.json exists and required keys are non-empty..."
          if [ ! -s "tf-outputs.json" ]; then
            echo "ERROR: tf-outputs.json not found (or empty) at repo root."
            echo "Hint: Terraform apply/output likely failed earlier."
            ls -la
            exit 1
          fi

          REQUIRED_KEYS=(cluster_name cluster_endpoint karpenter_controller_role_arn node_instance_profile_name)
          for key in "${REQUIRED_KEYS[@]}"; do
            value="$(jq -r --arg k "$key" '.[$k].value // empty' tf-outputs.json)"
            if [ -z "$value" ] || [ "$value" = "null" ]; then
              echo "ERROR: Missing/empty Terraform output: $key"
              echo "Available keys:"
              jq -r 'keys[]' tf-outputs.json || true
              exit 1
            fi
          done

          echo "Terraform outputs OK."
        shell: bash

      - name: Set up kubectl
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          aws eks update-kubeconfig --region "$AWS_REGION" --name "$(jq -r .cluster_name.value tf-outputs.json)"
        continue-on-error: false
      
      - name: Deploy Karpenter
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          helm repo add karpenter https://charts.karpenter.sh
          helm repo update
          CLUSTER_NAME=$(jq -r .cluster_name.value tf-outputs.json)
          CLUSTER_ENDPOINT=$(jq -r .cluster_endpoint.value tf-outputs.json)
          KARPENTER_ROLE_ARN=$(jq -r .karpenter_controller_role_arn.value tf-outputs.json)
          INSTANCE_PROFILE=$(jq -r .node_instance_profile_name.value tf-outputs.json)
          echo "Installing Karpenter with:"
          echo "  Cluster Name: $CLUSTER_NAME"
          echo "  Cluster Endpoint: $CLUSTER_ENDPOINT"
          echo "  Role ARN: $KARPENTER_ROLE_ARN"
          echo "  Instance Profile: $INSTANCE_PROFILE"
          helm install karpenter karpenter/karpenter \
            --namespace karpenter --create-namespace \
            --version 0.16.3 \
            --set serviceAccount.annotations."eks\.amazonaws\.com/role-arn"=$KARPENTER_ROLE_ARN \
            --set clusterName=$CLUSTER_NAME \
            --set clusterEndpoint=$CLUSTER_ENDPOINT \
            --set aws.defaultInstanceProfile=$INSTANCE_PROFILE \
            --set settings.clusterName=$CLUSTER_NAME
        continue-on-error: false

      - name: Wait for Karpenter to be Ready
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          echo "Waiting for Karpenter controller pods to be ready..."
          TIMEOUT=300
          ELAPSED=0
          while [ $ELAPSED -lt $TIMEOUT ]; do
            PODS=$(kubectl get pods -n karpenter -l app.kubernetes.io/name=karpenter -o json)
            READY_COUNT=$(echo "$PODS" | jq -r '.items[] | select(.status.containerStatuses[]?.ready == true) | .metadata.name' | wc -l | tr -d ' ')
            TOTAL_CONTAINERS=$(echo "$PODS" | jq -r '.items[].status.containerStatuses | length' | awk '{sum+=$1} END {print sum}')
            READY_CONTAINERS=$(echo "$PODS" | jq -r '.items[].status.containerStatuses[]? | select(.ready == true) | .name' | wc -l | tr -d ' ')
            
            echo "Ready containers: $READY_CONTAINERS/$TOTAL_CONTAINERS"
            kubectl get pods -n karpenter
            
            if [ "$READY_CONTAINERS" -ge 2 ] && [ "$READY_CONTAINERS" -eq "$TOTAL_CONTAINERS" ]; then
              echo "All Karpenter containers are ready!"
              break
            fi
            
            # Check for crash loops and show logs
            CRASHING=$(echo "$PODS" | jq -r '.items[] | select(.status.containerStatuses[]?.restartCount > 0) | .metadata.name' | head -1)
            if [ ! -z "$CRASHING" ]; then
              echo "Found crashing pod: $CRASHING"
              echo "=== Controller logs ==="
              kubectl logs $CRASHING -n karpenter -c controller --tail=50 || true
              echo "=== Webhook logs ==="
              kubectl logs $CRASHING -n karpenter -c webhook --tail=50 || true
            fi
            
            sleep 10
            ELAPSED=$((ELAPSED + 10))
          done
          
          if [ $ELAPSED -ge $TIMEOUT ]; then
            echo "Timeout waiting for Karpenter pods. Final status:"
            kubectl get pods -n karpenter -o wide
            kubectl get svc -n karpenter
            kubectl get endpoints -n karpenter
            echo "=== Checking for errors ==="
            kubectl describe pods -n karpenter -l app.kubernetes.io/name=karpenter | grep -A 10 "Events:" || true
            exit 1
          fi
          
          echo "Karpenter is ready!"
          kubectl get pods -n karpenter
          kubectl get svc -n karpenter
          kubectl get endpoints -n karpenter
        continue-on-error: false

      - name: Karpenter Webhook TLS Workaround
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          echo "Disabling Karpenter webhooks for TLS mismatch workaround..."
          kubectl delete mutatingwebhookconfiguration karpenter-mutating-webhook-configuration || true
          kubectl delete validatingwebhookconfiguration karpenter-validating-webhook-configuration || true
        continue-on-error: true

      - name: Install NVIDIA Device Plugin for GPU Support
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          kubectl apply -f https://github.com/NVIDIA/k8s-device-plugin/blob/v0.13.0/nvidia-device-plugin.yml
        continue-on-error: false

      - name: Apply Karpenter Provisioner
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: |
          # Workaround for Karpenter v0.16.3 webhook TLS issue
          # The webhook container's TLS certificate doesn't match the service name,
          # causing probes to fail and preventing the Provisioner from being applied.
          # Delete webhooks temporarily, apply Provisioner, then webhooks will be recreated by Karpenter.
          echo "Temporarily disabling webhooks to work around TLS issue..."
          kubectl delete mutatingwebhookconfiguration defaulting.webhook.provisioners.karpenter.sh --ignore-not-found || true
          kubectl delete validatingwebhookconfiguration validation.webhook.provisioners.karpenter.sh --ignore-not-found || true
          sleep 2
          echo "Applying Karpenter Provisioner..."
          kubectl apply -f ./Karpenter/main.yml
        continue-on-error: false

      - name: Deploy App/Job
        if: ${{ github.event.inputs.action != 'destroy' }}
        run: kubectl apply -f ./Karpenter/app-job.yml
        continue-on-error: false

      - name: Check GPU Provisioning Readiness
        if: ${{ github.event.inputs.action != 'destroy' }}
        id: gpu_check
        run: |
          # Check if NVIDIA device plugin is installed (required for GPU provisioning)
          if kubectl get daemonset -n kube-system | grep -q nvidia-device-plugin; then
            echo "âœ… NVIDIA device plugin detected - GPU provisioning may work"
            echo "gpu_ready=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ NVIDIA device plugin not found - GPU provisioning will likely fail"
            echo "Skipping GPU test job (GPU provisioning requires NVIDIA device plugin + GPU-enabled AMI)"
            echo "gpu_ready=false" >> $GITHUB_OUTPUT
          fi
        continue-on-error: true

      - name: Deploy GPU Test Job
        if: ${{ github.event.inputs.action != 'destroy' && steps.gpu_check.outputs.gpu_ready == 'true' }}
        run: |
          echo "Deploying GPU test job (NVIDIA device plugin detected)..."
          kubectl apply -f ./Karpenter/gpu-test-job.yml
        continue-on-error: true

      - name: Wait for GPU Test Job Completion
        if: ${{ github.event.inputs.action == 'deploy-and-destroy' && steps.gpu_check.outputs.gpu_ready == 'true' }}
        run: |
          # GPU test is best-effort. GPU provisioning requires:
          # 1. GPU-capable instance types (g4dn, g5, p3) in Provisioner âœ“
          # 2. NVIDIA device plugin installed in cluster (checked above)
          # 3. AMI with NVIDIA drivers (Karpenter default AMI may not have them)
          # 4. GPU instance availability in region/AZ
          echo "Waiting for GPU test job (timeout: 300s, reduced from 900s)..."
          if kubectl wait --for=condition=complete --timeout=300s job/gpu-test-job -n default 2>/dev/null; then
            echo "âœ… GPU test job completed successfully!"
            kubectl logs job/gpu-test-job -n default > gpu-job-logs.txt || echo "No logs found" > gpu-job-logs.txt
          else
            echo "âš ï¸ GPU test job did not complete within timeout"
            echo "Possible reasons:"
            echo "  - GPU instances not available in region/AZ"
            echo "  - AMI doesn't have NVIDIA drivers"
            echo "  - Karpenter v0.16.3 GPU detection limitations"
            echo "Capturing diagnostics..."
            kubectl logs job/gpu-test-job -n default > gpu-job-logs.txt 2>/dev/null || echo "No logs found" > gpu-job-logs.txt
            kubectl describe job/gpu-test-job -n default > gpu-job-describe.txt 2>/dev/null || true
            kubectl get pods -n default -l job-name=gpu-test-job -o wide > gpu-job-pods.txt 2>/dev/null || true
            # Check why provisioning failed
            kubectl get events --field-selector involvedObject.name=gpu-test-job --sort-by='.lastTimestamp' | tail -10 > gpu-job-events.txt 2>/dev/null || true
            echo "GPU provisioning diagnostics saved to artifacts."
          fi
        continue-on-error: true

      - name: GPU Test Skipped Notice
        if: ${{ github.event.inputs.action != 'destroy' && steps.gpu_check.outputs.gpu_ready != 'true' }}
        run: |
          echo "â„¹ï¸ GPU test job skipped - NVIDIA device plugin not installed"
          echo "To enable GPU provisioning:"
          echo "  1. Install NVIDIA device plugin: kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.1/nvidia-device-plugin.yml"
          echo "  2. Ensure Karpenter uses a GPU-enabled AMI (EKS Optimized AMI with GPU support)"
          echo "  3. Verify GPU instance types (g4dn, g5, p3) are available in your region/AZ"
          echo "" > gpu-job-logs.txt
          echo "GPU test skipped - NVIDIA device plugin not installed" > gpu-job-skipped.txt
        continue-on-error: true

      - name: Wait for Job Completion
        if: ${{ github.event.inputs.action == 'deploy-and-destroy' }}
        run: |
          kubectl wait --for=condition=complete --timeout=600s job/${{ github.event.inputs.job_name }} -n ${{ github.event.inputs.job_namespace }}
          kubectl logs job/${{ github.event.inputs.job_name }} -n ${{ github.event.inputs.job_namespace }} > job-logs.txt || echo "No logs found" > job-logs.txt
        continue-on-error: false

      - name: Collect Cluster Information
        if: always() && github.event.inputs.action != 'destroy'
        run: |
          # Collect cluster and node information
          kubectl get nodes -o json > nodes.json 2>/dev/null || echo "[]" > nodes.json
          kubectl get pods --all-namespaces -o json > pods.json 2>/dev/null || echo "[]" > pods.json
          kubectl get provisioner -o json > provisioners.json 2>/dev/null || echo "[]" > provisioners.json
          kubectl get events --all-namespaces --sort-by='.lastTimestamp' > events.txt 2>/dev/null || echo "No events found" > events.txt
          kubectl get pods -n karpenter -o json > karpenter-pods.json 2>/dev/null || echo "[]" > karpenter-pods.json
        continue-on-error: true

      - name: Generate Summary
        if: always()
        run: |
          echo "# ðŸš€ CI/CD Deployment Summary" > summary.md
          echo "" >> summary.md
          echo "**Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> summary.md
          echo "" >> summary.md
          
          # Workflow Information
          # Collect cluster and node information
          kubectl get nodes -o json > nodes.json 2>/dev/null || echo "[]" > nodes.json
          kubectl get pods --all-namespaces -o json > pods.json 2>/dev/null || echo "[]" > pods.json
          kubectl get provisioner -o json > provisioners.json 2>/dev/null || echo "[]" > provisioners.json
          kubectl get events --all-namespaces --sort-by='.lastTimestamp' > events.txt 2>/dev/null || echo "No events found" > events.txt
          kubectl get pods -n karpenter -o json > karpenter-pods.json 2>/dev/null || echo "[]" > karpenter-pods.json
        continue-on-error: true

      - name: Generate Summary
        if: always()
        run: |
          echo "# ðŸš€ CI/CD Deployment Summary" > summary.md
          echo "" >> summary.md
          echo "**Generated:** $(date -u +"%Y-%m-%d %H:%M:%S UTC")" >> summary.md
          echo "" >> summary.md
          
          # Workflow Information
          echo "## ðŸ“‹ Workflow Information" >> summary.md
          echo "" >> summary.md
          echo "| Field | Value |" >> summary.md
          echo "|-------|-------|" >> summary.md
          echo "| **Action** | \`${{ github.event.inputs.action }}\` |" >> summary.md
          echo "| **Workflow Status** | \`${{ job.status }}\` |" >> summary.md
          echo "| **Job Name** | \`${{ github.event.inputs.job_name }}\` |" >> summary.md
          echo "| **Job Namespace** | \`${{ github.event.inputs.job_namespace }}\` |" >> summary.md
          echo "| **Run ID** | \`${{ github.run_id }}\` |" >> summary.md
          echo "| **Commit** | \`${{ github.sha }}\` |" >> summary.md
          echo "" >> summary.md
          
          # Cluster Information
          if [ -f tf-outputs.json ]; then
            echo "## ðŸŽ¯ Cluster Information" >> summary.md
            echo "" >> summary.md
            echo "| Field | Value |" >> summary.md
            echo "|-------|-------|" >> summary.md
            echo "| **Cluster Name** | \`$(jq -r .cluster_name.value tf-outputs.json 2>/dev/null || echo "N/A")\` |" >> summary.md
            echo "| **Cluster Endpoint** | \`$(jq -r .cluster_endpoint.value tf-outputs.json 2>/dev/null || echo "N/A")\` |" >> summary.md
            echo "| **OIDC Issuer URL** | \`$(jq -r .cluster_oidc_issuer_url.value tf-outputs.json 2>/dev/null || echo "N/A")\` |" >> summary.md
            echo "| **Karpenter Controller Role ARN** | \`$(jq -r .karpenter_controller_role_arn.value tf-outputs.json 2>/dev/null || echo "N/A")\` |" >> summary.md
            echo "| **Node Instance Profile** | \`$(jq -r .node_instance_profile_name.value tf-outputs.json 2>/dev/null || echo "N/A")\` |" >> summary.md
            echo "" >> summary.md
          fi
          
          # Node Information
          if [ -f nodes.json ] && [ "$(jq '.items | length' nodes.json 2>/dev/null || echo 0)" -gt 0 ]; then
            echo "## ðŸ–¥ï¸ Node Information" >> summary.md
            echo "" >> summary.md
            echo "### Node Summary" >> summary.md
            echo "" >> summary.md
            TOTAL_NODES=$(jq '.items | length' nodes.json 2>/dev/null || echo 0)
            READY_NODES=$(jq '[.items[] | select(.status.conditions[]? | select(.type=="Ready" and .status=="True"))] | length' nodes.json 2>/dev/null || echo 0)
            KARPENTER_NODES=$(jq '[.items[] | select(.metadata.labels."karpenter.sh/provisioner-name" != null)] | length' nodes.json 2>/dev/null || echo 0)
            echo "- **Total Nodes:** $TOTAL_NODES" >> summary.md
            echo "- **Ready Nodes:** $READY_NODES" >> summary.md
            echo "- **Karpenter-Managed Nodes:** $KARPENTER_NODES" >> summary.md
            echo "" >> summary.md
            
            echo "### Node Details" >> summary.md
            echo "" >> summary.md
            echo "\`\`\`" >> summary.md
            kubectl get nodes -o custom-columns=NAME:.metadata.name,STATUS:.status.conditions[-1].type,ROLES:.metadata.labels.node-role\\.kubernetes\\.io/worker,INSTANCE-TYPE:.metadata.labels.node\\.kubernetes\\.io/instance-type,CPU:.status.capacity.cpu,MEMORY:.status.capacity.memory,KARPENTER:.metadata.labels.karpenter\\.sh/provisioner-name,AGE:.metadata.creationTimestamp 2>/dev/null || echo "Unable to retrieve node information" >> summary.md
            echo "\`\`\`" >> summary.md
            echo "" >> summary.md
            
            # Node resource utilization
            echo "### Node Resource Utilization" >> summary.md
            echo "" >> summary.md
            echo "\`\`\`" >> summary.md
            kubectl top nodes 2>/dev/null || echo "Metrics server not available" >> summary.md
            echo "\`\`\`" >> summary.md
            echo "" >> summary.md
          else
            echo "## ðŸ–¥ï¸ Node Information" >> summary.md
            echo "" >> summary.md
            echo "*No nodes found or cluster not accessible*" >> summary.md
            echo "" >> summary.md
          fi
          
          # Karpenter Status
          if [ -f karpenter-pods.json ] && [ "$(jq '.items | length' karpenter-pods.json 2>/dev/null || echo 0)" -gt 0 ]; then
            echo "## âš¡ Karpenter Status" >> summary.md
            echo "" >> summary.md
            echo "### Karpenter Pods" >> summary.md
            echo "" >> summary.md
            echo "\`\`\`" >> summary.md
            kubectl get pods -n karpenter -o wide 2>/dev/null || echo "Unable to retrieve Karpenter pods" >> summary.md
            echo "\`\`\`" >> summary.md
            echo "" >> summary.md
            
            # Provisioner Status
            if [ -f provisioners.json ] && [ "$(jq '.items | length' provisioners.json 2>/dev/null || echo 0)" -gt 0 ]; then
              echo "### Provisioner Configuration" >> summary.md
              echo "" >> summary.md
              echo "\`\`\`yaml" >> summary.md
              kubectl get provisioner -o yaml 2>/dev/null || echo "Unable to retrieve provisioner" >> summary.md
              echo "\`\`\`" >> summary.md
              echo "" >> summary.md
            fi
            
            # Karpenter Events
            echo "### Karpenter Events (Last 20)" >> summary.md
            echo "" >> summary.md
            echo "\`\`\`" >> summary.md
            kubectl get events --all-namespaces --sort-by='.lastTimestamp' | grep -i karpenter | tail -20 2>/dev/null || echo "No Karpenter events found" >> summary.md
            echo "\`\`\`" >> summary.md
            echo "" >> summary.md
          fi
          
          # Pod Information
          if [ -f pods.json ] && [ "$(jq '.items | length' pods.json 2>/dev/null || echo 0)" -gt 0 ]; then
            echo "## ðŸ“¦ Pod Information" >> summary.md
            echo "" >> summary.md
            TOTAL_PODS=$(jq '.items | length' pods.json 2>/dev/null || echo 0)
            RUNNING_PODS=$(jq '[.items[] | select(.status.phase=="Running")] | length' pods.json 2>/dev/null || echo 0)
            PENDING_PODS=$(jq '[.items[] | select(.status.phase=="Pending")] | length' pods.json 2>/dev/null || echo 0)
            FAILED_PODS=$(jq '[.items[] | select(.status.phase=="Failed")] | length' pods.json 2>/dev/null || echo 0)
            
            echo "### Pod Summary" >> summary.md
            echo "" >> summary.md
            echo "- **Total Pods:** $TOTAL_PODS" >> summary.md
            echo "- **Running:** $RUNNING_PODS" >> summary.md
            echo "- **Pending:** $PENDING_PODS" >> summary.md
            echo "- **Failed:** $FAILED_PODS" >> summary.md
            echo "" >> summary.md
            
            echo "### Pod Details" >> summary.md
            echo "" >> summary.md
            echo "\`\`\`" >> summary.md
            kubectl get pods --all-namespaces -o custom-columns=NAMESPACE:.metadata.namespace,NAME:.metadata.name,STATUS:.status.phase,NODE:.spec.nodeName,CPU-REQ:.spec.containers[0].resources.requests.cpu,MEM-REQ:.spec.containers[0].resources.requests.memory,AGE:.metadata.creationTimestamp 2>/dev/null | head -50 || echo "Unable to retrieve pod information" >> summary.md
            echo "\`\`\`" >> summary.md
            echo "" >> summary.md
            
            # Job Status
            if [ "${{ github.event.inputs.action }}" == "deploy-and-destroy" ] || [ "${{ github.event.inputs.action }}" == "deploy" ]; then
              echo "### Job Status: ${{ github.event.inputs.job_name }}" >> summary.md
              echo "" >> summary.md
              echo "\`\`\`" >> summary.md
              kubectl get job ${{ github.event.inputs.job_name }} -n ${{ github.event.inputs.job_namespace }} -o wide 2>/dev/null || echo "Job not found or not accessible" >> summary.md
              echo "\`\`\`" >> summary.md
              echo "" >> summary.md
              
              if [ -f job-logs.txt ]; then
                echo "### Job Logs" >> summary.md
                echo "" >> summary.md
                echo "\`\`\`" >> summary.md
                head -100 job-logs.txt >> summary.md
                if [ $(wc -l < job-logs.txt) -gt 100 ]; then
                  echo "" >> summary.md
                  echo "... (truncated, see full logs in artifact)" >> summary.md
                fi
                echo "\`\`\`" >> summary.md
                echo "" >> summary.md
              fi
            fi
          fi
          
          # GPU Test Job Results
          if [ -f gpu-job-logs.txt ]; then
            echo "## ðŸ§ª GPU Autoscaling Test" >> summary.md
            echo "" >> summary.md
            echo "### GPU Test Job Logs" >> summary.md
            echo "" >> summary.md
            echo '\`\`\`' >> summary.md
            head -50 gpu-job-logs.txt >> summary.md
            if [ $(wc -l < gpu-job-logs.txt) -gt 50 ]; then
              echo "... (truncated, see full logs in artifact)" >> summary.md
            fi
            echo '\`\`\`' >> summary.md
            echo "" >> summary.md
            # Check for success marker
            if grep -q 'GPU test successful!' gpu-job-logs.txt; then
              echo "**Result:** âœ… GPU node was provisioned and test ran successfully." >> summary.md
            else
              echo "**Result:** âŒ GPU node was NOT provisioned or test failed." >> summary.md
            fi
            echo "" >> summary.md
          fi
          
          # Resource Summary
          echo "## ðŸ“Š Resource Summary" >> summary.md
          echo "" >> summary.md
          if [ -f nodes.json ] && [ "$(jq '.items | length' nodes.json 2>/dev/null || echo 0)" -gt 0 ]; then
            TOTAL_CPU=$(jq '[.items[].status.capacity.cpu] | map(tonumber? // 0) | add' nodes.json 2>/dev/null || echo 0)
            TOTAL_MEMORY=$(jq '[.items[].status.capacity.memory] | map(gsub("Ki"; "") | tonumber? // 0) | add' nodes.json 2>/dev/null || echo 0)
            TOTAL_MEMORY_GB=$((TOTAL_MEMORY / 1024 / 1024))
            echo "- **Total Cluster CPU:** ${TOTAL_CPU} cores" >> summary.md
            echo "- **Total Cluster Memory:** ~${TOTAL_MEMORY_GB} GB" >> summary.md
            echo "" >> summary.md
          fi
          
          # Karpenter Provisioning Activity
          if [ -f events.txt ]; then
            echo "## ðŸ”„ Karpenter Provisioning Activity" >> summary.md
            echo "" >> summary.md
            PROVISIONING_EVENTS=$(grep -i "karpenter\|provision\|launch\|node" events.txt | tail -30 || echo "")
            if [ ! -z "$PROVISIONING_EVENTS" ]; then
              echo "\`\`\`" >> summary.md
              echo "$PROVISIONING_EVENTS" >> summary.md
              echo "\`\`\`" >> summary.md
            else
              echo "*No provisioning events found*" >> summary.md
            fi
            echo "" >> summary.md
          fi
          
          # Errors and Warnings
          echo "## âš ï¸ Errors and Warnings" >> summary.md
          echo "" >> summary.md
          if [ -f events.txt ]; then
            ERROR_EVENTS=$(grep -i "error\|warning\|failed" events.txt | tail -20 || echo "")
            if [ ! -z "$ERROR_EVENTS" ]; then
              echo "\`\`\`" >> summary.md
              echo "$ERROR_EVENTS" >> summary.md
              echo "\`\`\`" >> summary.md
            else
              echo "*No errors or warnings found*" >> summary.md
            fi
          else
            echo "*Unable to retrieve events*" >> summary.md
          fi
          echo "" >> summary.md
          
          # Footer
          echo "---" >> summary.md
          echo "" >> summary.md
          echo "**Workflow Run:** [View on GitHub](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> summary.md
          echo "" >> summary.md
          echo "*This summary was automatically generated by the CI/CD workflow.*" >> summary.md
        shell: bash
        continue-on-error: true

      - name: Upload Summary and Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: deployment-summary
          if-no-files-found: warn
          path: |
            summary.md
            gpu-job-logs.txt
            gpu-job-describe.txt
            gpu-job-pods.txt
            gpu-job-events.txt
            gpu-job-skipped.txt
            nodes.json
            pods.json
            provisioners.json
            karpenter-pods.json
            events.txt
            job-logs.txt
            tf-outputs.json
          retention-days: 7

      - name: Pre-destroy Cleanup (Terminate Karpenter Instances)
        if: always() && github.event.inputs.action != 'deploy'
        run: |
          set -euo pipefail
          if [ ! -s "tf-outputs.json" ]; then
            echo "tf-outputs.json not found; skipping Karpenter instance cleanup."
            exit 0
          fi

          CLUSTER_NAME="$(jq -r .cluster_name.value tf-outputs.json)"
          echo "Attempting to terminate any Karpenter-launched instances for cluster: $CLUSTER_NAME"

          # Karpenter tags resources with karpenter.k8s.aws/cluster=<clusterName>
          INSTANCE_IDS="$(aws ec2 describe-instances \
            --region "$AWS_REGION" \
            --filters \
              "Name=tag:karpenter.k8s.aws/cluster,Values=$CLUSTER_NAME" \
              "Name=instance-state-name,Values=pending,running,stopping,stopped" \
            --query 'Reservations[].Instances[].InstanceId' \
            --output text || true)"

          if [ -z "${INSTANCE_IDS// }" ]; then
            echo "No Karpenter-tagged instances found."
            exit 0
          fi

          echo "Terminating instances: $INSTANCE_IDS"
          aws ec2 terminate-instances --region "$AWS_REGION" --instance-ids $INSTANCE_IDS >/dev/null
          echo "Waiting for instances to terminate..."
          aws ec2 wait instance-terminated --region "$AWS_REGION" --instance-ids $INSTANCE_IDS
          echo "Karpenter instance cleanup complete."
        shell: bash
        continue-on-error: true

      - name: Terraform Destroy (Always)
        if: always() && github.event.inputs.action != 'deploy'
        working-directory: ./terraform/environments/dev
        run: terraform destroy -auto-approve
        continue-on-error: false